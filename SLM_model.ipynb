{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22184cc8-c915-4b17-a312-befe64660bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing requirments\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900cf5a3-4a2a-48ce-9ccb-df2107293889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download nltk punkt tokenizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7f32592-2eaa-4ea4-ba36-7ad0f994ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset \n",
    "df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\project\\Plagiarism_Checker_AI\\Dataset\\train_snli.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb1d009-a08b-4f12-8222-804ca4e11e2c",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d32de507-bd4e-45aa-bc26-d6a73f9c0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning column names\n",
    "df.columns = ['sentence1', 'sentence2', 'label']\n",
    "df = df.dropna(subset=['sentence1', 'sentence2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4fa9cd2-564c-4395-98a9-5e0ef43b9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentences for SLM training\n",
    "tokenized_s1 = [word_tokenize(sent.lower()) for sent in df['sentence1']]\n",
    "tokenized_s2 = [word_tokenize(sent.lower()) for sent in df['sentence2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19671d5e-724c-4ec7-aa5d-876f6ac6fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data for 3-gram SLM\n",
    "n = 3\n",
    "train_data_s1, vocab_s1 = padded_everygram_pipeline(n, tokenized_s1)\n",
    "train_data_s2, vocab_s2 = padded_everygram_pipeline(n, tokenized_s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a7cd64d-8b97-4214-a273-48c1507edf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train two separate 3-gram models\n",
    "model_s1 = MLE(n)\n",
    "model_s1.fit(train_data_s1, vocab_s1)\n",
    "\n",
    "model_s2 = MLE(n)\n",
    "model_s2.fit(train_data_s2, vocab_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "512f9f8c-b2c3-4649-8151-3789f2c02c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute log probability of a sentence for a model\n",
    "import math\n",
    "def sentence_log_prob(model, sentence):\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    ngrams = list(nltk.ngrams(tokens, n, pad_left=True, pad_right=True,\n",
    "                               left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
    "    log_prob = 0.0\n",
    "    for ng in ngrams:\n",
    "        context = ng[:-1]\n",
    "        word = ng[-1]\n",
    "        prob = model.score(word, context)\n",
    "        # Avoid log(0) by smoothing zero probabilities\n",
    "        if prob > 0:\n",
    "            log_prob += math.log(prob)\n",
    "        else:\n",
    "            log_prob += math.log(1e-12)  # Very small smoothing value\n",
    "    return log_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86909eaa-64b5-4fbc-896d-41edcaa9af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log probabilities as features\n",
    "df['log_prob_s1_model'] = df['sentence1'].apply(lambda x: sentence_log_prob(model_s1, x))\n",
    "df['log_prob_s2_model'] = df['sentence2'].apply(lambda x: sentence_log_prob(model_s2, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4638e2c6-4214-4503-834d-e9d8056c45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally compute absolute difference between scores as another feature\n",
    "df['abs_log_prob_diff'] = abs(df['log_prob_s1_model'] - df['log_prob_s2_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0569d97b-d3c1-45fe-be07-ff604853ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the SLM features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_slm = scaler.fit_transform(df[['log_prob_s1_model', 'log_prob_s2_model', 'abs_log_prob_diff']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "151899c2-08c8-462f-b954-8496b03e3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# 1. TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "vectorizer.fit(pd.concat([df['sentence1'], df['sentence2']]))\n",
    "\n",
    "X1_vec = vectorizer.transform(df['sentence1'])\n",
    "X2_vec = vectorizer.transform(df['sentence2'])\n",
    "\n",
    "# 2. Add vector comparison features (optional but helpful)\n",
    "X_diff = abs(X1_vec - X2_vec)\n",
    "X_mult = X1_vec.multiply(X2_vec)\n",
    "\n",
    "# 3. Combine sparse vectors into a single matrix\n",
    "X_tfidf = hstack([X1_vec, X2_vec, X_diff, X_mult])  # shape: (n_samples, 20K or less)\n",
    "\n",
    "# 4. Combine with SLM log-prob features (dense → sparse)\n",
    "slm_features = csr_matrix(df[['log_prob_s1_model', 'log_prob_s2_model', 'abs_log_prob_diff']].values)\n",
    "\n",
    "# 5. Final input: sparse TF-IDF + dense SLM features\n",
    "X_final = hstack([X_tfidf, slm_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da2e4410-9b6e-45b3-9a12-cac3ea1246cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels for classification\n",
    "X = df[['log_prob_s1_model', 'log_prob_s2_model', 'abs_log_prob_diff']]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c93955-fa78-4269-b035-76989d40a077",
   "metadata": {},
   "source": [
    "## MODEL FITTING AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2aaeea07-b464-4976-a9c1-de06ca94fdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training Accuracy: 0.8610\n",
      "✅ Testing Accuracy: 0.8332\n",
      "Accuracy: 0.8332471350409669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83     36837\n",
      "           1       0.82      0.86      0.84     36637\n",
      "\n",
      "    accuracy                           0.83     73474\n",
      "   macro avg       0.83      0.83      0.83     73474\n",
      "weighted avg       0.83      0.83      0.83     73474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Split and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "# 8. Evaluate\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"✅ Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"✅ Testing Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "740a77df-8d1c-49d8-826e-12e4d014361f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ngram_model_s2.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'plagiarism_model.pkl')\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "# Save the SLM feature scaler (if used)\n",
    "joblib.dump(scaler, 'slm_scaler.pkl')\n",
    "\n",
    "joblib.dump(model_s1, 'ngram_model_s1.pkl')\n",
    "joblib.dump(model_s2, 'ngram_model_s2.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616af8b-18c1-4456-8ec1-762a7003402d",
   "metadata": {},
   "source": [
    "## DETECTION DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e141f2c5-95f5-41dc-9967-47989b3a1f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import math\n",
    "import joblib\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "# download it once before executiton\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Load trained model and scaler\n",
    "svm_model = joblib.load('plagiarism_model.pkl')\n",
    "scaler = joblib.load('slm_scaler.pkl')\n",
    "model_s1 = joblib.load('ngram_model_s1.pkl')\n",
    "model_s2 = joblib.load('ngram_model_s2.pkl')\n",
    "\n",
    "# Preprocessing function to compute log-probability\n",
    "def sentence_log_prob(model, sentence, n=3):\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    ngrams = list(nltk.ngrams(tokens, n, pad_left=True, pad_right=True,\n",
    "                               left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
    "    log_prob = 0.0\n",
    "    for ng in ngrams:\n",
    "        context = ng[:-1]\n",
    "        word = ng[-1]\n",
    "        prob = model.score(word, context)\n",
    "        if prob > 0:\n",
    "            log_prob += math.log(prob)\n",
    "        else:\n",
    "            log_prob += math.log(1e-12)  # Avoid log(0)\n",
    "    return log_prob\n",
    "\n",
    "# Inference function\n",
    "def predict_plagiarism(sentence1, sentence2):\n",
    "    log_prob1 = sentence_log_prob(model_s1, sentence1)\n",
    "    log_prob2 = sentence_log_prob(model_s2, sentence2)\n",
    "    abs_diff = abs(log_prob1 - log_prob2)\n",
    "\n",
    "    features = [[log_prob1, log_prob2, abs_diff]]\n",
    "    features_scaled = scaler.transform(features)\n",
    "\n",
    "    prediction = svm_model.predict(features_scaled)[0]\n",
    "    proba = svm_model.predict_proba(features_scaled)[0] if hasattr(svm_model, \"predict_proba\") else None\n",
    "\n",
    "    print(f\"Sentence 1: {sentence1}\")\n",
    "    print(f\"Sentence 2: {sentence2}\")\n",
    "\n",
    "    print(f\"Prediction: {'Plagiarized' if prediction == 1 else 'Not Plagiarized'}\")\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3fcb4b4b-32be-46be-8d9c-4b452477312c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: The dog barked loudly at night.\n",
      "Sentence 2: A dog made noise during the night.\n",
      "Prediction: Plagiarized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predict_plagiarism(\"The dog barked loudly at night.\", \"A dog made noise during the night.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94556a9d-c73d-4fe6-afd1-57c355114668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd22adb7-b21d-4d58-b63e-3a05b0b64f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
